{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Models as Web Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive model as a web endpoint\n",
    "In order for a machine learning model to be useful, you need a way of sharing the results with other services and applications within your organization. While you can precompute results and save them to a database using a batch pipeline approach, it’s often necessary to respond to requests in real-time with up-to-date information. One way of achieving this goal is by setting up a predictive model as a web endpoint that can be invoked from other services.\n",
    "\n",
    "This chapter shows how to set up this functionality for both scikit-learn and Keras models, and introduces Python tools that can help scale up this functionality.\n",
    "\n",
    "## Hosting and consuming web endpoints\n",
    "It’s good to build experience in both hosting and consuming web endpoints when building out model pipelines with Python. In some cases, a predictive model needs to pull data points from other services before making a prediction, such as needing to pull additional attributes about a user’s history as input to feature engineering. In this chapter, we’ll focus on JSON based services because it is a popular data format and works well with Python’s data types.\n",
    "\n",
    "## Model as an endpoint\n",
    "A model as an endpoint is a system that provides a prediction in response to a set of parameters. These parameters can be a feature vector, image, or other types of data that are used as input to a predictive model. The endpoint then makes a prediction and returns the results, typically as a JSON payload. The benefits of setting up a model this way are that other systems can use the predictive model, it provides a real-time result, and can be used within a broader data pipeline.\n",
    "\n",
    "## Chapter learning outcomes\n",
    "In this chapter, we will:\n",
    "\n",
    "- Call web services using Python.\n",
    "- Set up endpoints.\n",
    "- Save models so that they can be used in production environments.\n",
    "- Host scikit-learn and Keras predictive models.\n",
    "- Scale up a service with Gunicorn and Heroku.\n",
    "- Build an interactive web application with Plotly Dash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we host a predictive model, we’ll use Python to call a web service and to process the result. After showing how to process a web response, we’ll set up our own service that echoes the passed-in message back to the caller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries to install\n",
    "There are few different libraries we’ll need to install for the examples in this chapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install  requests==2.23.0 Flask==1.1.4 gunicorn==20.1.0 mlflow==1.25.1 pillow==9.1.0 dash==2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionalities\n",
    "These libraries provide the following functionalities:\n",
    "\n",
    "- Requests: provides functions for GET and POST methods\n",
    "- Flask: enables functions to be exposed as HTTP locations\n",
    "- Gunicorn: a WSGI server that enables hosting Flask apps in production environments\n",
    "- Mlflow: a model library that provides model persistence\n",
    "- Pillow: a fork of the Python Imaging Library\n",
    "- Dash: enables writing interactive web apps in Python\n",
    "\n",
    "Many of the tools for building web services in the Python ecosystem work well with Flask. For example, Gunicorn can be used to host Flask applications at the production scale, and the Dash library builds on top of Flask.\n",
    "\n",
    "## Heroku \n",
    "To get started with making web requests in Python, we’ll use the Cat Facts Heroku app.\n",
    "\n",
    "Heroku is a cloud platform that works well for hosting Python applications that we’ll explore later in this chapter.\n",
    "\n",
    "## Example \n",
    "The Cat Facts service provides a simple API that provides a JSON response containing interesting tidbits about felines. We can use the /facts/random endpoint to retrieve a random fact using the requests library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{'status': {'verified': True, 'sentCount': 1}, '_id': '591f98783b90f7150a19c1a0', '__v': 0, 'text': 'The average lifespan of an outdoor-only cat is about 3 to 5 years while an indoor-only cat can live 16 years or much longer.', 'source': 'api', 'updatedAt': '2020-08-23T20:20:01.611Z', 'type': 'cat', 'createdAt': '2018-06-03T20:20:02.291Z', 'deleted': False, 'used': False, 'user': '5a9ac18c7478810ea6c06381'}\n",
      "The average lifespan of an outdoor-only cat is about 3 to 5 years while an indoor-only cat can live 16 years or much longer.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "result = requests.get(\"http://cat-fact.herokuapp.com/facts/random\")\n",
    "print(result)\n",
    "print(result.json())\n",
    "print(result.json()['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet loads the requests library and then uses the ``get`` function to perform an HTTP get for the passed in URL. The result is a response object that provides a response code and payload if available. In this case, the payload can be processed using the ``json`` function, which returns the payload as a Python dictionary. The three print statements show the response code, the full payload, and the value for the ``text`` key in the returned dictionary object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Echo Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
